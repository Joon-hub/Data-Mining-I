{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below if you are using Google Colab to mount your Google Drive in your Colab instance. Adjust the path to the files in your Google Drive as needed if it differs.\n",
    "\n",
    "If you do not use Google Colab, running the cell will simply do nothing, so do not worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    %cd 'drive/My Drive/Colab Notebooks/08_Association'\n",
    "except ImportError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Association\n",
    "## Frequent Itemsets & Association Rules\n",
    "- Frequent Itemset\n",
    "    - Support count: Frequency of an itemset\n",
    "    - Support: relative frequency of an itemset (wrt. all transactions)\n",
    "- Association Rule 𝑋→𝑌\n",
    "    - Support: Support of the itemset 𝑋 ∪ 𝑌\n",
    "    - Confidence: relative frequency of 𝑋 ∪ 𝑌 wrt. 𝑋\n",
    "        - “If an itemsetcontains 𝑋, in x% of the cases it also contains 𝑌”\n",
    "    - Lift: confidence of rule 𝑋→𝑌divided by support of consequent 𝑌\n",
    "        - \\>1X and Y are positively correlated\n",
    "        - <1X and Y are negatively correlated\n",
    "        - =1X and Y are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python Library for Frequent Itemsets & Association Rules\n",
    "\n",
    "Scikit-learn does not include algorithms for frequent itemset generation and association rules. In this exercise, we will use [the implementations from the Orange library](https://orange3-associate.readthedocs.io/en/latest/scripting.html).\n",
    "\n",
    "This package offers you three functions:\n",
    "- [```frequent_itemsets()```](https://orange3-associate.readthedocs.io/en/latest/scripting.html#fpgrowth.frequent_itemsets): Generates frequent itemsets from a dataset\n",
    "- [```association_rules()```](https://orange3-associate.readthedocs.io/en/latest/scripting.html#fpgrowth.association_rules): Generates association rules from frequent itemsets\n",
    "- [```rules_stats()```](https://orange3-associate.readthedocs.io/en/latest/scripting.html#fpgrowth.rules_stats): Calculates additional statistics for association rules from frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install -q -U Orange3-Associate\n",
    "import pandas as pd\n",
    "shopping = pd.read_excel('ShoppingBaskets.xls')\n",
    "shopping_data = shopping.drop('BasketNo', axis=1)\n",
    "shopping_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Frequent Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from orangecontrib.associate.fpgrowth import frequent_itemsets\n",
    "\n",
    "# calculate the frequent itemsets\n",
    "itemsets = dict(frequent_itemsets(shopping_data.values, 0.20))\n",
    "\n",
    "# store the results in a dataframe\n",
    "rows = []\n",
    "for itemset, support_count in itemsets.items():\n",
    "    domain_names= \",\".join([shopping_data.columns[item_index] for item_index in itemset])\n",
    "    rows.append((len(itemset), support_count, support_count / len(shopping_data.index), domain_names))\n",
    "\n",
    "item_set_table = pd.DataFrame(rows, columns=[\"size\", \"support count\", \"support\", \"items\"])\n",
    "item_set_table.sort_values('support', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the results using conditions on the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(item_set_table[ item_set_table['items'].str.contains('ThinkPad X220') ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orangecontrib.associate.fpgrowth import association_rules, rules_stats\n",
    "\n",
    "# calculate association rules from the itemsets\n",
    "rules = association_rules(itemsets, 0.70)\n",
    "\n",
    "# calculate statistics about the rules and store them in a dataframe\n",
    "rows = []\n",
    "for premise, conclusion, sup, conf,cov, strength, lift, leverage  in rules_stats(rules, itemsets, len(shopping_data)):\n",
    "    premise_names = \",\".join([shopping_data.columns[item_index] for item_index in premise])\n",
    "    conclusion_names = \",\".join([shopping_data.columns[item_index] for item_index in conclusion])\n",
    "    rows.append((premise_names, conclusion_names, sup, conf,cov, strength, lift, leverage))\n",
    "\n",
    "pd.DataFrame(rows, columns = ['Premise', 'Conclusion', 'Support', 'Confidence', 'Coverage', 'Strength', 'Lift', 'Leverage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Preprocessing in pandas\n",
    "\n",
    "We now look at some more options for data preprocessing using pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "adult_arff_data, adult_arff_meta = arff.loadarff(open('adult-dataset-tweaked.arff', 'r'))\n",
    "adult = pd.DataFrame(adult_arff_data)\n",
    "adult = adult.applymap(lambda x: x.decode('utf8') if hasattr(x, 'decode') else x)\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge several categorical values, we can use the ```replace()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "adult['education'].replace(['Bachelors','Masters','Assoc-acdm','Prof-school','Assoc-voc', 'Doctorate'], 'Other-Grad', inplace=True)\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we don't want to specify all values individually, we can also replace all values that satisfy a condition using the ```loc[]``` accessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult.loc[ adult['native-country'] != 'United-States', 'native-country'] = 'Non-US'\n",
    "adult.sort_values(by='native-country').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to using scikit-learn KBinsDiscretizer, we can also discretize numeric values using pandas [```cut()``` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult['age'] = pd.cut(adult['age'], [0, 20, 65, 100],labels=['low', 'middle', 'high'])\n",
    "adult.head()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
